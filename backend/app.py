from typing import List, Dict
from contextlib import asynccontextmanager
from datetime import datetime

from fastapi import FastAPI, Depends, HTTPException, BackgroundTasks, Query
from fastapi.middleware.cors import CORSMiddleware
from sqlalchemy.orm import Session
import uvicorn
import asyncio
import logging
import redis
from kafka import KafkaProducer, KafkaConsumer
import json
import time
import subprocess
import threading
from flight_service import FlightService

logger = logging.getLogger(__name__)

from database import get_db, create_tables
from config import settings

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç—ã (–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è –≤ lifespan)
redis_client = None
kafka_producer = None
KAFKA_ENABLED = False


def start_kafka_services():
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç Zookeeper –∏ Kafka –≤ —Ñ–æ–Ω–æ–≤—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–∞—Ö"""

    def run_zookeeper():
        try:
            process = subprocess.Popen(
                [
                    "/kafka/bin/zookeeper-server-start.sh",
                    "/kafka/config/zookeeper.properties",
                ],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
            )
            logger.info("‚úÖ Zookeeper started")
            return process
        except Exception as e:
            logger.error(f"‚ùå Failed to start Zookeeper: {e}")
            return None

    def run_kafka():
        try:
            # –ñ–¥–µ–º –Ω–µ–º–Ω–æ–≥–æ —á—Ç–æ–±—ã Zookeeper –∑–∞–ø—É—Å—Ç–∏–ª—Å—è
            time.sleep(10)
            process = subprocess.Popen(
                ["/kafka/bin/kafka-server-start.sh", "/kafka/config/server.properties"],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
            )
            logger.info("‚úÖ Kafka started")
            return process
        except Exception as e:
            logger.error(f"‚ùå Failed to start Kafka: {e}")
            return None

    # –ó–∞–ø—É—Å–∫–∞–µ–º –≤ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –ø–æ—Ç–æ–∫–∞—Ö
    import threading

    zk_thread = threading.Thread(target=run_zookeeper, daemon=True)
    kafka_thread = threading.Thread(target=run_kafka, daemon=True)

    zk_thread.start()
    kafka_thread.start()

    logger.info("üöÄ Kafka services starting in background threads...")


async def init_redis():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Redis —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏"""
    global redis_client
    max_retries = 5
    for i in range(max_retries):
        try:
            redis_client = redis.Redis(host="redis", port=6379, decode_responses=True, socket_connect_timeout=5)
            redis_client.ping()
            logger.info("‚úÖ Redis connected successfully")
            return True
        except Exception as e:
            logger.warning(f"Redis connection attempt {i+1}/{max_retries} failed: {e}")
            if i < max_retries - 1:
                await asyncio.sleep(2)

    logger.error("‚ùå Redis connection failed after all retries")
    return False


async def init_kafka():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Kafka —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏"""
    global kafka_producer, KAFKA_ENABLED
    max_retries = 5
    for i in range(max_retries):
        try:
            kafka_producer = KafkaProducer(
                bootstrap_servers=["localhost:9092"],  # ‚Üê –ò–ó–ú–ï–ù–ò–¢–¨ –° 'kafka:9092' –Ω–∞ 'localhost:9092'
                value_serializer=lambda v: json.dumps(v).encode("utf-8"),
                retries=3,
                request_timeout_ms=10000,
            )
            # –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
            kafka_producer.send("health-check", {"status": "test"})
            KAFKA_ENABLED = True
            logger.info("‚úÖ Kafka connected successfully")
            return True
        except Exception as e:
            logger.warning(f"Kafka connection attempt {i+1}/{max_retries} failed: {e}")
            if i < max_retries - 1:
                await asyncio.sleep(3)

    logger.warning("‚ùå Kafka connection failed, running without Kafka")
    KAFKA_ENABLED = False
    return False


def send_kafka_event(topic: str, event_data: dict):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–±—ã—Ç–∏–π –≤ Kafka"""
    if KAFKA_ENABLED and kafka_producer:
        try:
            event_data["timestamp"] = datetime.utcnow().isoformat()
            event_data["service"] = "pobeda-backend"
            kafka_producer.send(topic, event_data)
            logger.info(f"üì® Sent event to {topic}: {event_data.get('event_type', 'unknown')}")
        except Exception as e:
            logger.error(f"Failed to send Kafka event to {topic}: {e}")


# –§–æ–Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏
background_tasks = set()


async def background_price_updater():
    """–§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ü–µ–Ω"""
    while True:
        try:
            from database import SessionLocal
            from background_service import BackgroundPriceUpdater

            db = SessionLocal()
            updater = BackgroundPriceUpdater(db)

            logger.info("üöÄ Starting background price update...")
            updated_count = await updater.update_all_popular_routes()

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–±—ã—Ç–∏–µ –≤ Kafka
            send_kafka_event(
                "background-jobs",
                {
                    "event_type": "price_update_completed",
                    "routes_updated": updated_count,
                },
            )

            logger.info(f"‚úÖ Background update finished: {updated_count} routes updated")
            db.close()

        except Exception as e:
            logger.error(f"Error in background price updater: {e}")
            send_kafka_event(
                "error-logs",
                {
                    "event_type": "background_job_error",
                    "job": "price_updater",
                    "error": str(e),
                },
            )

        await asyncio.sleep(60 * 60)  # 1 hour


async def background_cities_updater():
    """–§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∞–∫—Ç–∏–≤–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤"""
    while True:
        try:
            from database import SessionLocal
            from city_service import CityService

            db = SessionLocal()
            city_service = CityService(db)

            logger.info("üöÄ Starting background cities update...")
            updated_count = await city_service.update_active_cities_in_db()

            send_kafka_event(
                "background-jobs",
                {
                    "event_type": "cities_update_completed",
                    "active_cities": updated_count,
                },
            )

            logger.info(f"‚úÖ Background cities update finished: {updated_count} active cities")
            db.close()

        except Exception as e:
            logger.error(f"Error in background cities updater: {e}")
            send_kafka_event(
                "error-logs",
                {
                    "event_type": "background_job_error",
                    "job": "cities_updater",
                    "error": str(e),
                },
            )

        await asyncio.sleep(24 * 60 * 60)  # 24 hours


@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    logger.info("üöÄ Starting Pobeda Parser API with Embedded Kafka...")

    # ‚úÖ –î–û–ë–ê–í–¨–¢–ï –≠–¢–ò 4 –°–¢–†–û–ß–ö–ò:
    # –ó–∞–ø—É—Å–∫–∞–µ–º Kafka —Å–µ—Ä–≤–∏—Å—ã
    start_kafka_services()

    # –ñ–¥–µ–º –Ω–µ–º–Ω–æ–≥–æ –ø–µ—Ä–µ–¥ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–µ–π Kafka –∫–ª–∏–µ–Ω—Ç–∞
    await asyncio.sleep(25)
    # ‚úÖ –ö–û–ù–ï–¶ –î–û–ë–ê–í–õ–ï–ù–ò–Ø

    create_tables()
    logger.info("‚úÖ Database tables created")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Redis –∏ Kafka
    redis_ok = await init_redis()
    kafka_ok = await init_kafka()

    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–æ–Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏
    price_task = asyncio.create_task(background_price_updater())
    cities_task = asyncio.create_task(background_cities_updater())

    background_tasks.add(price_task)
    background_tasks.add(cities_task)

    price_task.add_done_callback(background_tasks.discard)
    cities_task.add_done_callback(background_tasks.discard)

    logger.info("‚úÖ Background tasks started")

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–±—ã—Ç–∏–µ –æ —Å—Ç–∞—Ä—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
    send_kafka_event(
        "system-events",
        {
            "event_type": "app_started",
            "redis_connected": redis_ok,
            "kafka_connected": kafka_ok,
        },
    )

    yield

    # Shutdown
    logger.info("üõë Shutting down Pobeda Parser API...")

    for task in background_tasks:
        task.cancel()
    await asyncio.gather(*background_tasks, return_exceptions=True)

    # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
    if redis_client:
        redis_client.close()
    if kafka_producer:
        kafka_producer.close()

    logger.info("‚úÖ Pobeda Parser API stopped")


app = FastAPI(
    title="Pobeda Parser API",
    description="API –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ü–µ–Ω –∞–≤–∏–∞–∫–æ–º–ø–∞–Ω–∏–∏ –ü–æ–±–µ–¥–∞",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
    openapi_url="/openapi.json",
    lifespan=lifespan,
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# Health check —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤
@app.get("/")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Å–∏—Å—Ç–µ–º—ã"""
    redis_status = "unknown"
    if redis_client:
        try:
            redis_client.ping()
            redis_status = "healthy"
        except Exception as e:
            redis_status = f"error: {e}"

    return {
        "message": "Pobeda Parser API —Ä–∞–±–æ—Ç–∞–µ—Ç! üöÄ",
        "status": "healthy",
        "services": {
            "redis": redis_status,
            "kafka": "enabled" if KAFKA_ENABLED else "disabled",
        },
        "timestamp": datetime.utcnow().isoformat(),
    }


# –¢–µ—Å—Ç–æ–≤—ã–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã
@app.get("/test-redis")
async def test_redis():
    """–¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Redis"""
    if not redis_client:
        raise HTTPException(status_code=503, detail="Redis not initialized")

    try:
        # –¢–µ—Å—Ç –∑–∞–ø–∏—Å–∏
        test_key = f"test:{datetime.utcnow().strftime('%H%M%S')}"
        redis_client.set(test_key, "test_value", ex=60)

        # –¢–µ—Å—Ç —á—Ç–µ–Ω–∏—è
        value = redis_client.get(test_key)

        send_kafka_event(
            "test-events",
            {
                "event_type": "redis_test",
                "status": "success",
                "key": test_key,
                "value": value,
            },
        )

        return {
            "status": "success",
            "message": "Redis connection OK",
            "data": {"key": test_key, "value": value},
        }
    except Exception as e:
        send_kafka_event("error-logs", {"event_type": "redis_test_error", "error": str(e)})
        raise HTTPException(status_code=500, detail=f"Redis test failed: {e}")


@app.get("/test-kafka")
async def test_kafka():
    """–¢–µ—Å—Ç –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ Kafka"""
    if not KAFKA_ENABLED:
        raise HTTPException(status_code=503, detail="Kafka not available")

    try:
        test_event = {
            "event_type": "kafka_test",
            "message": "Test message from Pobeda Parser API",
            "timestamp": datetime.utcnow().isoformat(),
        }

        send_kafka_event("test-events", test_event)

        return {
            "status": "success",
            "message": "Kafka event sent successfully",
            "event": test_event,
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Kafka test failed: {e}")


@app.get("/cache-test")
async def cache_test():
    """–¢–µ—Å—Ç Redis –∏ Kafka –≤–º–µ—Å—Ç–µ"""
    if not redis_client:
        raise HTTPException(status_code=503, detail="Redis not initialized")

    try:
        # –¢–µ—Å—Ç Redis
        redis_client.set("cache_test_key", "cache_test_value", ex=60)
        value = redis_client.get("cache_test_key")

        # –¢–µ—Å—Ç Kafka
        send_kafka_event(
            "test-events",
            {"event_type": "cache_test", "action": "cache_test", "redis_value": value},
        )

        return {"redis": value, "kafka": "event_sent", "status": "success"}
    except Exception as e:
        send_kafka_event("error-logs", {"event_type": "cache_test_error", "error": str(e)})
        raise HTTPException(status_code=500, detail=f"Cache test failed: {e}")


# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
@app.post("/api/logs/frontend", summary="–ü—Ä–∏–µ–º –ª–æ–≥–æ–≤ —Å —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞")
async def receive_frontend_logs(log_data: dict, db: Session = Depends(get_db)):
    """–ü—Ä–∏–Ω–∏–º–∞–µ—Ç –ª–æ–≥–∏ —Å —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –≤ ELK"""
    try:
        # –õ–æ–≥–∏—Ä—É–µ–º –Ω–∞ –±–µ–∫–µ–Ω–¥–µ
        logger.info("Frontend log received", extra={"frontend_data": log_data})

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Kafka
        send_kafka_event(
            "frontend-logs",
            {
                "event_type": "frontend_log",
                "level": log_data.get("level"),
                "message": log_data.get("message"),
                "user_agent": log_data.get("userAgent"),
                "url": log_data.get("url"),
            },
        )

        return {"status": "success"}
    except Exception as e:
        logger.error(f"Error processing frontend log: {e}")
        send_kafka_event("error-logs", {"event_type": "log_processing_error", "error": str(e)})
        return {"status": "error", "message": str(e)}


@app.post("/api/logs/backend", summary="–õ–æ–≥–∏ –±–µ–∫–µ–Ω–¥–∞")
async def receive_backend_logs(log_data: dict):
    """–ü—Ä–∏–Ω–∏–º–∞–µ—Ç –ª–æ–≥–∏ —Å –¥—Ä—É–≥–∏—Ö —Å–µ—Ä–≤–∏—Å–æ–≤ –±–µ–∫–µ–Ω–¥–∞"""
    logger.info("Backend log received", extra={"backend_data": log_data})

    send_kafka_event("backend-logs", {"event_type": "backend_log", "data": log_data})

    return {"status": "success"}


@app.get("/cities")
async def get_cities(skip: int = 0, limit: int = 500, db: Session = Depends(get_db)):
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –≥–æ—Ä–æ–¥–æ–≤"""
    from city_service import CityService
    from models import City

    city_service = CityService(db)

    # –û–±–Ω–æ–≤–ª—è–µ–º –≥–æ—Ä–æ–¥–∞ –∏–∑ API
    await city_service.update_cities_from_api()

    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –≥–æ—Ä–æ–¥–∞ –∏–∑ –ë–î
    cities = db.query(City).offset(skip).limit(limit).all()

    send_kafka_event(
        "api-requests",
        {
            "event_type": "cities_request",
            "endpoint": "/cities",
            "cities_count": len(cities),
        },
    )

    return cities


@app.get(
    "/cities/active",
    summary="–ü–æ–ª—É—á–∏—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–µ –≥–æ—Ä–æ–¥–∞",
    description="–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ª—å–∫–æ –≥–æ—Ä–æ–¥–∞, –æ—Ç–∫—É–¥–∞ –ï–°–¢–¨ —Ä–µ–π—Å—ã –ü–æ–±–µ–¥—ã",
)
async def get_active_cities(
    skip: int = Query(0, description="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π (–¥–ª—è –ø–∞–≥–∏–Ω–∞—Ü–∏–∏)"),
    limit: int = Query(500, description="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã—Ö –∑–∞–ø–∏—Å–µ–π"),
    db: Session = Depends(get_db),
):
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Ç–æ–ª—å–∫–æ –ê–ö–¢–ò–í–ù–´–• –≥–æ—Ä–æ–¥–æ–≤ (–æ—Ç–∫—É–¥–∞ –µ—Å—Ç—å —Ä–µ–π—Å—ã)"""
    from models import City

    cities = db.query(City).filter(City.is_active == True).offset(skip).limit(limit).all()

    send_kafka_event(
        "api-requests",
        {
            "event_type": "cities_request",
            "endpoint": "/cities/active",
            "cities_count": len(cities),
        },
    )

    return {
        "total_active": db.query(City).filter(City.is_active == True).count(),
        "cities": cities,
    }


@app.get(
    "/flights/search",
    summary="–ü–æ–∏—Å–∫ —Ä–µ–π—Å–æ–≤ –Ω–∞ –º–µ—Å—è—Ü",
    description="–ò—â–µ—Ç —Ä–µ–π—Å—ã –º–µ–∂–¥—É –¥–≤—É–º—è –≥–æ—Ä–æ–¥–∞–º–∏ –Ω–∞ 30 –¥–Ω–µ–π –≤–ø–µ—Ä–µ–¥",
)
async def search_flights(
    origin: str = Query(
        ...,
        description="–ö–æ–¥ –≥–æ—Ä–æ–¥–∞ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∏–∑ –∞–∫—Ç–∏–≤–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤, (–Ω–∞–ø—Ä–∏–º–µ—Ä: MOW, LED, AER)",
    ),
    destination: str = Query(..., description="–ö–æ–¥ –≥–æ—Ä–æ–¥–∞ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ –∞–∫—Ç–∏–≤–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤"),
    promo_code: str = Query(None, description="–ü—Ä–æ–º–æ–∫–æ–¥ –¥–ª—è –ø–æ–∏—Å–∫–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)"),
    db: Session = Depends(get_db),
):
    """–ü–æ–∏—Å–∫ —Ä–µ–π—Å–æ–≤ –º–µ–∂–¥—É –≥–æ—Ä–æ–¥–∞–º–∏ –Ω–∞ –º–µ—Å—è—Ü –≤–ø–µ—Ä–µ–¥"""
    from models import City
    from flight_service import FlightService

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≥–æ—Ä–æ–¥–∞ –∞–∫—Ç–∏–≤–Ω—ã–µ
    origin_city = db.query(City).filter(City.code == origin, City.is_active == True).first()
    destination_city = db.query(City).filter(City.code == destination, City.is_active == True).first()

    if not origin_city:
        raise HTTPException(
            status_code=400,
            detail=f"–ì–æ—Ä–æ–¥ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∏—è '{origin}' –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –Ω–µ –∞–∫—Ç–∏–≤–µ–Ω",
        )
    if not destination_city:
        raise HTTPException(
            status_code=400,
            detail=f"–ì–æ—Ä–æ–¥ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è '{destination}' –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –Ω–µ –∞–∫—Ç–∏–≤–µ–Ω",
        )

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–±—ã—Ç–∏–µ –æ –Ω–∞—á–∞–ª–µ –ø–æ–∏—Å–∫–∞
    send_kafka_event(
        "search-events",
        {
            "event_type": "search_started",
            "origin": origin,
            "destination": destination,
            "promo_code": promo_code,
        },
    )

    flight_service = FlightService(db)
    search_result = await flight_service.search_flights_month(origin, destination, promo_code)

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–±—ã—Ç–∏–µ –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –ø–æ–∏—Å–∫–∞
    send_kafka_event(
        "search-events",
        {
            "event_type": "search_completed",
            "origin": origin,
            "destination": destination,
            "flights_found": len(search_result["flights"]),
            "promo_code": promo_code,
            "is_complete": search_result["is_complete"],
        },
    )

    return {
        "origin": origin_city.name_ru,
        "destination": destination_city.name_ru,
        "promo_code": promo_code,
        "total_days_searched": search_result["total_days_searched"],
        "days_with_data": search_result["days_with_data"],
        "is_complete": search_result["is_complete"],
        "has_retry_data": search_result["has_retry_data"],
        "flights": search_result["flights"],
    }


@app.get(
    "/flights/anywhere",
    summary="–ü–æ–∏—Å–∫ '–ö—É–¥–∞ —É–≥–æ–¥–Ω–æ'",
    description="–ò—â–µ—Ç —Å–∞–º—ã–µ –¥–µ—à–µ–≤—ã–µ —Ä–µ–π—Å—ã –∏–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –≥–æ—Ä–æ–¥–∞ –≤–æ –í–°–ï –¥–æ—Å—Ç—É–ø–Ω—ã–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –Ω–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –º–µ—Å—è—Ü",
)
async def search_anywhere(
    origin: str = Query(
        ...,
        description="–ö–æ–¥ –≥–æ—Ä–æ–¥–∞ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä: MOW, LED, AER). –ü–æ–ª—É—á–∏—Ç—å –∫–æ–¥—ã –≥–æ—Ä–æ–¥–æ–≤: /cities/active",
    ),
    months_ahead: int = Query(1, description="–ù–∞ —Å–∫–æ–ª—å–∫–æ –º–µ—Å—è—Ü–µ–≤ –≤–ø–µ—Ä–µ–¥ –∏—Å–∫–∞—Ç—å (1-6 –º–µ—Å—è—Ü–µ–≤, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1)"),
    promo_code: str = Query(None, description="–ü—Ä–æ–º–æ–∫–æ–¥ –¥–ª—è –ø–æ–∏—Å–∫–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)"),
    max_price: float = Query(None, description="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞ –±–∏–ª–µ—Ç–∞ –≤ —Ä—É–±–ª—è—Ö (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)"),
    db: Session = Depends(get_db),
):
    """–ü–æ–∏—Å–∫ —Å–∞–º—ã—Ö –¥–µ—à–µ–≤—ã—Ö —Ä–µ–π—Å–æ–≤ –∏–∑ –≥–æ—Ä–æ–¥–∞ –≤ –ª—é–±—ã–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è"""
    from anywhere_service import AnywhereService

    # –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    if months_ahead < 1 or months_ahead > 6:
        raise HTTPException(status_code=400, detail="months_ahead –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç 1 –¥–æ 6")

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–±—ã—Ç–∏–µ –æ –Ω–∞—á–∞–ª–µ –ø–æ–∏—Å–∫–∞ "–ö—É–¥–∞ —É–≥–æ–¥–Ω–æ"
    send_kafka_event(
        "anywhere-search",
        {
            "event_type": "anywhere_search_started",
            "origin": origin,
            "months_ahead": months_ahead,
            "max_price": max_price,
        },
    )

    anywhere_service = AnywhereService(db)
    results = await anywhere_service.search_anywhere(origin, months_ahead, promo_code, max_price)

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–±—ã—Ç–∏–µ –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –ø–æ–∏—Å–∫–∞
    send_kafka_event(
        "anywhere-search",
        {
            "event_type": "anywhere_search_completed",
            "origin": origin,
            "destinations_found": len(results),
            "months_ahead": months_ahead,
        },
    )

    return {
        "origin": origin,
        "months_ahead": months_ahead,
        "promo_code": promo_code,
        "max_price": max_price,
        "total_destinations_found": len(results),
        "cheapest_flights": results,
    }


# –û—Å–Ω–æ–≤–Ω—ã–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –¥–ª—è –≥–æ—Ä–æ–¥–æ–≤
@app.get("/cities/for-frontend", summary="–ì–æ—Ä–æ–¥–∞ –¥–ª—è –≤—ã–±–æ—Ä–∞ –Ω–∞ —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–µ")
async def get_cities_for_frontend(db: Session = Depends(get_db)):
    """–ü–æ–ª—É—á–∏—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–µ –≥–æ—Ä–æ–¥–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞"""
    from city_service import CityService

    city_service = CityService(db)
    cities = city_service.get_cities_for_frontend()

    return {"cities": cities, "total": len(cities)}


@app.post("/admin/update-active-cities", summary="–û–±–Ω–æ–≤–∏—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–µ –≥–æ—Ä–æ–¥–∞")
async def update_active_cities(db: Session = Depends(get_db)):
    """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∞–∫—Ç–∏–≤–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤"""
    from city_service import CityService

    city_service = CityService(db)
    updated_count = await city_service.update_active_cities_in_db()

    return {
        "status": "success",
        "message": f"Updated {updated_count} active cities",
        "updated_count": updated_count,
    }


@app.get("/cities/active", summary="–ê–∫—Ç–∏–≤–Ω—ã–µ –≥–æ—Ä–æ–¥–∞")
async def get_active_cities(db: Session = Depends(get_db)):
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∞–∫—Ç–∏–≤–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤"""
    from models import City

    cities = db.query(City).filter(City.is_active == True).all()
    return {"total": len(cities), "cities": cities}


if __name__ == "__main__":
    uvicorn.run("app:app", host="0.0.0.0", port=8000, reload=settings.DEBUG)
